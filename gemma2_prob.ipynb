{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gheto\\miniconda3\\envs\\detoate\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading shards: 100%|██████████| 2/2 [02:05<00:00, 62.93s/it] \n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.44s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Check if GPU is available and set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model_name = \"google/gemma-2-2b-it\"  # Replace with the specific model name, e.g., \"EleutherAI/gpt-neo-1.3B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)  # Move model to GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The 'max_batch_size' argument of HybridCache is deprecated and will be removed in v4.46. Use the more precisely named 'batch_size' argument instead.\n",
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
     ]
    }
   ],
   "source": [
    "input_text = \"\"\"Write me a poem about Machine Learning.\"\"\"\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\").to(device)\n",
    "generated_ids = model.generate(\n",
    "        inputs[\"input_ids\"],\n",
    "        max_new_tokens=50,\n",
    "    )\n",
    "print(tokenizer.decode(generated_ids[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM response: Describe the sights and sounds of a bustling farmers' market.\n",
      "\n",
      "**Sights:**\n",
      "\n",
      "* **A vibrant tapestry of colors:** Baskets overflowing with ripe tomatoes, plump peaches, and vibrant purple eggplant.\n",
      "* **The bounty of the season:** Rows of fresh herbs, leafy greens, and colorful vegetables in neat stacks.\n",
      "* **The aroma of fresh produce:** The sweet scent of ripe strawberries\n",
      "Probabilities: [0.7119027972221375, 0.5827901363372803, 0.799126923084259, 0.988342821598053, 0.9432348012924194, 0.9016574621200562, 0.9562946557998657, 0.9221857190132141, 0.1828395277261734, 0.23922263085842133, 0.4149479568004608, 0.9890844225883484, 0.5946714878082275, 0.8827874064445496, 0.08403302729129791, 0.8383487462997437, 0.9995378255844116, 0.23847390711307526, 0.2732764184474945, 0.8776777386665344, 0.07814806699752808, 0.43571847677230835, 0.7018110156059265, 0.6783096790313721, 0.2933952510356903, 0.3008807301521301, 0.5884259343147278, 0.7055785059928894, 0.08480974286794662, 0.9994035959243774, 0.9982024431228638, 0.19641941785812378, 0.03374568372964859, 0.9928730726242065, 0.7284719347953796, 0.2748064398765564, 0.9854649901390076, 0.2113439291715622, 0.8077756762504578, 0.11005008965730667, 0.581920862197876, 0.5792166590690613, 0.17683684825897217, 0.9270228743553162, 0.9008296132087708, 0.934029757976532, 0.36902809143066406, 0.30880966782569885, 0.09025182574987411, 0.10932397842407227, 0.09489236027002335, 0.6612859964370728, 0.8466033339500427, 0.9997157454490662, 0.9994121789932251, 0.17444390058517456, 0.1820022463798523, 0.9876870512962341, 0.3107593357563019, 0.3560616075992584, 0.9804953336715698, 0.23590587079524994, 0.29646483063697815, 0.6400697827339172, 0.9985711574554443, 0.34664884209632874, 0.23880457878112793]\n",
      "Perplexity: 2.3128964375024776\n",
      "{'\\n\\n': 0.9016574621200562, '**': 0.5827901363372803, 'S': 0.799126923084259, 'ights': 0.988342821598053, ':**': 0.9804953336715698, '*': 0.9997157454490662, ' **': 0.9994121789932251, 'A': 0.1828395277261734, ' vibrant': 0.2933952510356903, ' tapestry': 0.4149479568004608, ' of': 0.9985711574554443, ' colors': 0.5946714878082275, ' Baskets': 0.08403302729129791, ' overflowing': 0.8383487462997437, ' with': 0.9995378255844116, ' ripe': 0.34664884209632874, ' tomatoes': 0.2732764184474945, ',': 0.9008296132087708, ' plump': 0.07814806699752808, ' peaches': 0.43571847677230835, ' and': 0.934029757976532, ' purple': 0.3008807301521301, ' eggplant': 0.5884259343147278, '.': 0.6612859964370728, '\\n': 0.8466033339500427, 'The': 0.17444390058517456, ' bounty': 0.03374568372964859, ' the': 0.7284719347953796, ' season': 0.2748064398765564, ' Rows': 0.2113439291715622, ' fresh': 0.3107593357563019, ' herbs': 0.581920862197876, ' leafy': 0.17683684825897217, ' greens': 0.9270228743553162, ' colorful': 0.36902809143066406, ' vegetables': 0.30880966782569885, ' in': 0.09025182574987411, ' neat': 0.10932397842407227, ' stacks': 0.09489236027002335, ' aroma': 0.1820022463798523, ' produce': 0.3560616075992584, ' The': 0.23590587079524994, ' sweet': 0.29646483063697815, ' scent': 0.6400697827339172, ' strawberries': 0.23880457878112793}\n"
     ]
    }
   ],
   "source": [
    "input_text = \"Describe the sights and sounds of a bustling farmers' market.\"\n",
    "\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\").to(device)  \n",
    "\n",
    "with torch.no_grad():\n",
    "    generated_ids = model.generate(\n",
    "        **inputs,\n",
    "        max_length=80,\n",
    "        eos_token_id=tokenizer.eos_token_id,  \n",
    "        do_sample=True,\n",
    "        temperature=0.5,\n",
    "        top_k=30,\n",
    "        top_p=0.9\n",
    "    )\n",
    "generated_text = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "print(f\"LLM response: {generated_text}\")\n",
    "\n",
    "input_length = inputs[\"input_ids\"].shape[1]  \n",
    "generated_tokens = generated_ids[0][input_length:]  \n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(generated_ids).logits\n",
    "\n",
    "generated_logits = logits[0, input_length - 1:-1, :]  \n",
    "generated_probs = torch.softmax(generated_logits, dim=-1)\n",
    "\n",
    "\n",
    "token_probs = [generated_probs[i, token].item() for i, token in enumerate(generated_tokens)]\n",
    "\n",
    "log_probs = [math.log(p) for p in token_probs if p > 0]\n",
    "perplexity = math.exp(-sum(log_probs) / len(log_probs))\n",
    "\n",
    "print(f\"Probabilities: {token_probs}\")\n",
    "print(f\"Perplexity: {perplexity}\")\n",
    "\n",
    "token_probs_dict = {tokenizer.decode(token): prob for token, prob in zip(generated_tokens, token_probs)}\n",
    "\n",
    "print(token_probs_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'**': 0.5827901363372803, 'S': 0.799126923084259, 'ights': 0.988342821598053, ':**': 0.9804953336715698, '\\n\\n': 0.9016574621200562, '*': 0.9997157454490662, ' **': 0.9994121789932251, 'A': 0.1828395277261734, ' vibrant': 0.2933952510356903, ' tapestry': 0.4149479568004608, ' of': 0.9985711574554443, ' colors': 0.5946714878082275, ' Baskets': 0.08403302729129791, ' overflowing': 0.8383487462997437, ' with': 0.9995378255844116, ' ripe': 0.34664884209632874, ' tomatoes': 0.2732764184474945, ',': 0.9008296132087708, ' plump': 0.07814806699752808, ' peaches': 0.43571847677230835, ' and': 0.934029757976532, ' purple': 0.3008807301521301, ' eggplant': 0.5884259343147278, '.': 0.6612859964370728, '\\n': 0.8466033339500427, 'The': 0.17444390058517456, ' bounty': 0.03374568372964859, ' the': 0.7284719347953796, ' season': 0.2748064398765564, ' Rows': 0.2113439291715622, ' fresh': 0.3107593357563019, ' herbs': 0.581920862197876, ' leafy': 0.17683684825897217, ' greens': 0.9270228743553162, ' colorful': 0.36902809143066406, ' vegetables': 0.30880966782569885, ' in': 0.09025182574987411, ' neat': 0.10932397842407227, ' stacks': 0.09489236027002335, ' aroma': 0.1820022463798523, ' produce': 0.3560616075992584, ' The': 0.23590587079524994, ' sweet': 0.29646483063697815, ' scent': 0.6400697827339172, ' strawberries': 0.23880457878112793}\n"
     ]
    }
   ],
   "source": [
    "token_probs_dict_pad = {tokenizer.decode(token): prob for token, prob in zip(generated_tokens[1:], token_probs[1:])}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "def generate_response(prompt):\n",
    "    input_text = prompt\n",
    "\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\").to(device)  \n",
    "\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        generated_ids = model.generate(\n",
    "            **inputs,\n",
    "            max_length=80,\n",
    "            eos_token_id=tokenizer.eos_token_id,  \n",
    "            do_sample=True,\n",
    "            temperature=0.5,\n",
    "            top_k=30,\n",
    "            top_p=0.9\n",
    "        )\n",
    "    end_time = time.time()\n",
    "    resp_time = end_time - start_time\n",
    "    generated_text = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "    # print(f\"Generated text: {generated_text}\")\n",
    "\n",
    "    input_length = inputs[\"input_ids\"].shape[1]  \n",
    "    generated_tokens = generated_ids[0][input_length:]  \n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(generated_ids).logits\n",
    "\n",
    "    generated_logits = logits[0, input_length - 1:-1, :]  \n",
    "    generated_probs = torch.softmax(generated_logits, dim=-1)\n",
    "\n",
    "\n",
    "    token_probs = [generated_probs[i, token].item() for i, token in enumerate(generated_tokens)]\n",
    "\n",
    "    log_probs = [math.log(p) for p in token_probs if p > 0]\n",
    "    perplexity = math.exp(-sum(log_probs) / len(log_probs))\n",
    "\n",
    "    # print(f\"Token probabilities: {token_probs}\")\n",
    "    # print(f\"Perplexity: {perplexity}\")\n",
    "\n",
    "# starting from the second token, because the first one is always an endline\n",
    "    token_probs_dict = {tokenizer.decode(token): prob for token, prob in zip(generated_tokens[1:], token_probs[1:])}\n",
    "    \n",
    "    only_output_text = generated_text[len(input_text):]\n",
    "    return {\"response_time\":resp_time, \"generated_text\": only_output_text[2:], \"perplexity\": perplexity, \"token_probabilities\": token_probs_dict}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Describe the sights and sounds of a bustling farmers' market.\n",
      "Write about a sunrise you saw from the top of a mountain.\n",
      "Imagine walking through a rainforestâ€”describe the experience.\n",
      "Write about a dog chasing a frisbee in a park.\n",
      "Describe the moment a child learns to ride a bicycle.\n",
      "Write about cooking a favorite meal and the smells that fill the kitchen.\n",
      "Describe a walk through a quiet snow-covered forest.\n",
      "Write about the first time you swam in the ocean.\n",
      "Describe the scene of a carnival at night.\n",
      "Write about planting flowers in a garden.\n",
      "Describe a picnic on a sunny day by a lake.\n",
      "Write about the moment before a race starts.\n",
      "Describe a train journey through scenic landscapes.\n",
      "Write about feeding ducks in a pond.\n",
      "Describe a library filled with old, dusty books.\n",
      "Write about climbing a tree as a child.\n",
      "Describe the experience of tasting a new fruit for the first time.\n",
      "Write about a thunderstorm rolling in on a summer evening.\n",
      "Describe the atmosphere of an outdoor concert.\n",
      "Write about a kite flying high in a blue sky.\n",
      "Write about the feeling of waiting for an important phone call.\n",
      "Describe what freedom feels like.\n",
      "Write about a moment when you felt pure joy.\n",
      "Describe the feeling of losing something important.\n",
      "Write about the sense of calm after a stressful day.\n",
      "Describe the bittersweet moment of saying goodbye.\n",
      "Write about the excitement of meeting someone new.\n",
      "Describe how love can feel like a warm embrace.\n",
      "Write about the experience of nostalgia triggered by a familiar smell.\n",
      "Describe the anticipation of opening a gift.\n",
      "Write about the relief after overcoming a difficult challenge.\n",
      "Describe the feeling of standing on stage for the first time.\n",
      "Write about the sense of wonder when looking at the night sky.\n",
      "Describe the gratitude felt after receiving unexpected help.\n",
      "Write about the nervousness before an important interview.\n",
      "Describe how disappointment feels like an empty room.\n",
      "Write about the courage it takes to speak up for yourself.\n",
      "Describe the feeling of hope when seeing the first signs of spring.\n",
      "Write about the joy of reuniting with an old friend.\n",
      "Describe the resilience needed to keep going during tough times.\n",
      "Write about a day when everything went wrong but ended perfectly.\n",
      "Describe a camping trip that was full of unexpected surprises.\n",
      "Write about a trip to the zoo and the most memorable animal encounter.\n",
      "Describe the events leading up to a surprise birthday party.\n",
      "Write about the journey of finding a lost pet.\n",
      "Describe a family road trip and its funniest moment.\n",
      "Write about a day spent exploring a new city.\n",
      "Describe the events of a school play and what happened backstage.\n",
      "Write about a time you helped a stranger and how they responded.\n",
      "Describe a journey through a haunted house attraction.\n",
      "Write about a morning routine interrupted by a power outage.\n",
      "Describe an adventure in a sunflower field.\n",
      "Write about learning a new skill and the steps you took to master it.\n",
      "Describe an unexpected detour that turned into a memorable experience.\n",
      "Write about a summer day spent at a beach with friends.\n",
      "Describe the chaos and fun of a family holiday dinner.\n",
      "Write about finding a hidden treasure while cleaning your attic.\n",
      "Describe a time you got lost and how you found your way back.\n",
      "Write about building a sandcastle and the waves washing it away.\n",
      "Describe a day in the life of a delivery driver during the holidays.\n",
      "Explain how to make a perfect cup of coffee.\n",
      "Write about fixing a flat tire on a bicycle.\n",
      "Describe how to guide someone to bake cookies step by step.\n",
      "Write about teaching someone how to play a simple tune on the piano.\n",
      "Explain how youâ€™d set up a tent in the wilderness.\n",
      "Write about organizing a bookshelf by genre and size.\n",
      "Describe how you would solve a Rubik's Cube (or try to!).\n",
      "Write about guiding someone through creating a paper airplane.\n",
      "Explain how to navigate a city using only a paper map.\n",
      "Write about how you would teach someone to whistle.\n",
      "Describe fixing a dripping faucet at home.\n",
      "Explain how to wrap a gift for a special occasion.\n",
      "Write about organizing a successful surprise party.\n",
      "Describe how to prepare a picnic lunch for a hiking trip.\n",
      "Write about packing for a weekend getaway to the mountains.\n",
      "Explain how to help someone learn how to ride a scooter.\n",
      "Describe cleaning up a messy room efficiently.\n",
      "Write about designing and planting a small flower garden.\n",
      "Explain how to care for a new pet.\n",
      "Write about teaching a child to tie their shoelaces.\n",
      "Imagine youâ€™ve found a time machineâ€”write about your first trip.\n",
      "Describe a city where everything floats in the air.\n",
      "Write about a conversation with a talking tree.\n",
      "Imagine discovering a hidden underground library.\n",
      "Describe a day in a world where people can fly.\n",
      "Write about an encounter with an alien visitor.\n",
      "Imagine a robot becoming your best friendâ€”describe your adventures.\n",
      "Describe a magical forest and the creatures that live there.\n",
      "Write about being shrunk to the size of an ant for a day.\n",
      "Imagine finding a key that opens any doorâ€”where does it take you?\n",
      "Describe the moment you discover you can control the weather.\n",
      "Write about a future world where humans live underwater.\n",
      "Imagine finding a suitcase full of mysterious artifacts.\n",
      "Describe a castle that moves from place to place.\n",
      "Write about your first day as a character in a video game.\n",
      "Imagine animals could talkâ€”describe a debate between a cat and a dog.\n",
      "Write about discovering a secret portal in your backyard.\n",
      "Describe a dream where youâ€™re the ruler of a kingdom.\n",
      "Write about inventing a gadget that solves an everyday problem.\n",
      "Imagine waking up in a world where music controls everything.\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "\n",
    "with open(\"responses.json\", \"r\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "new_output = {}\n",
    "\n",
    "for prompt in data.keys():\n",
    "    print(prompt)\n",
    "    resp = generate_response(prompt)\n",
    "    new_output[prompt] = resp\n",
    "\n",
    "    with open(\"responses_new.json\", \"w\") as file:\n",
    "        json.dump(new_output, file, indent=4)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detoate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
